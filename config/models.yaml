embedding:
  model: mxbai-embed-large

orchestrators:
  light:
    model: qwen3:1.7b
    max_tokens: 4096
  heavy:
    model: qwen3:14b
    max_tokens: 8192

code_synthesis:
  primary:
    # Large models (try first if memory allows)
    - qwen2.5-coder:14b
    - deepseek-coder:latest
    - codellama:13b
    # Medium models (good balance)
    - qwen2.5-coder:7b
    - deepseek-coder:6.7b
    - codellama:7b
    # Small models (fallback for low memory)
    - qwen2.5:3b
    - qwen2.5:1.5b
    - tinyllama
    - stable-code:3b
    - codegemma:2b
  
  specialized:
    math: wizard-math:latest
    reasoning: qwq:32b
    
general:
  - llama3.1:latest
  - tulu3:latest
  - llama3:latest

json_functions:
  model: llama3.2:latest

model_params:
  temperature: 0.7
  top_p: 0.95
  repeat_penalty: 1.1